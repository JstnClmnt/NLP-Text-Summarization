{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-Summarization",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JstnClmnt/NLP-Text-Summarization/blob/master/NLP_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruSXNIBlSo6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import re\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "275RJ-74TJUi",
        "colab_type": "code",
        "outputId": "ddc1a600-92a9-4452-fb80-5860e2d23947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJB2GnwJUZJU",
        "colab_type": "code",
        "outputId": "0e442a7b-6439-42b4-f4c3-8cc68fd65694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/drive/Team Drives/AI Lords/NLP-Text-Summarization/data/news_summary_more.csv\",encoding=\"latin-1\")\n",
        "df.head()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUBzG4lWrCW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
        "df['headlines'] = df['headlines'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
        "df=df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdIkHeY5pbOW",
        "colab_type": "code",
        "outputId": "a9b4766b-e488-413f-eaa0-274beaf4a1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(df[\"text\"], df[\"headlines\"], test_size=0.20, random_state=42)\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saurav Kant  an alumnus of upGrad and IIIT B s PG Program in Machine learning and Artificial Intelligence  was a Sr Systems Engineer at Infosys with almost   years of work experience  The program and upGrad s     degree career support helped him transition to a Data Scientist at Tech Mahindra with     salary hike  upGrad s Online Power Learning has powered   lakh  careers \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxBxffJa5Q3H",
        "colab_type": "code",
        "outputId": "0f6a3338-2b13-4668-ea5b-84c120804cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "X_train_tokenized=[i.split() for i in X_train]\n",
        "X_test_tokenized=[i.split() for i in X_test]\n",
        "print(X_train_tokenized[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['Hollywood', 'actress', 'Kate', 'Winslet', 'has', 'joined', 'the', 'cast', 'of', 'Titanic', 'director', 'James', 'Cameron', 's', 'upcoming', 'films', 'in', 'the', 'Avatar', 'franchise', 'making', 'this', 'their', 'first', 'venture', 'together', 'after', 'years', 'of', 'Titanic', 's', 'release', 'Cameron', 'said', 'Kate', 'and', 'I', 'have', 'been', 'looking', 'for', 'something', 'to', 'do', 'together', 'since', 'our', 'collaboration', 'on', 'Titanic', 'I', 'can', 't', 'wait', 'to', 'see', 'her', 'bring', 'the', 'character', 'of', 'Ronal', 'to', 'life']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZfUX-LmsONj",
        "colab_type": "code",
        "outputId": "f8d174e0-5ddf-41f1-d468-e41a405a3ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train_tokenized=[word_tokenize(i) for i in y_train]\n",
        "y_test_tokenized=[word_tokenize(i) for i in y_test]\n",
        "print(y_train_tokenized[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Kate', 'Winslet', 'to', 'work', 'with', 'Titanic', 'maker', 'after', 'years']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqdSY1PqqeL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = set([])\n",
        "for s in X_train_tokenized:\n",
        "    for w in s:\n",
        "      if len(w)>1:\n",
        "        words.add(w.lower())\n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IqWLGE2v3-h",
        "colab_type": "code",
        "outputId": "2e631384-8053-45cd-c624-6940e454e523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-16 20:22:51--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-05-16 20:22:52--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  15.3MB/s    in 80s     \n",
            "\n",
            "2019-05-16 20:24:12 (10.2 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E767o2kOv7QC",
        "colab_type": "code",
        "outputId": "40466dc4-52ae-42a3-9fd5-dd4e4c6ca00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip \"glove.6B.zip\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xl0omApv-UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.300d.txt',encoding=\"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iogkAHIowA3M",
        "colab_type": "code",
        "outputId": "f84f6408-20db-4405-9fc5-cde9cec3d2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_sentences_X, test_sentences_X,train_sentences_Y,test_sentences_Y = [], [], [], []\n",
        "\n",
        "EMB_DIM=300\n",
        "num_words=len(word2index)+1\n",
        "print(\"Number of Words:\"+str(num_words))\n",
        "\n",
        "for s in X_train_tokenized:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "      if len(w)>1:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)\n",
        "    \n",
        "for s in X_test_tokenized:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "      if len(w)>1:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        "  \n",
        "for s in y_train_tokenized:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "      if len(w)>1:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_Y.append(s_int)\n",
        "    \n",
        "for s in y_test_tokenized:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "       if len(w)>1:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_Y.append(s_int)\n",
        "\n",
        "\n",
        "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
        "print(\"Max Length: \"+str(MAX_LENGTH))  # 271\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "#y_train=to_categorical(y_train)\n",
        "#y_test=to_categorical(y_test)\n",
        "print(train_sentences_X[0])\n",
        "print(train_sentences_Y[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Words:70551\n",
            "Max Length: 68\n",
            "[56111   242 36778 57525 40584 20559 17827  9676 33886 70252 36661 16572\n",
            " 45867 26789 49917 48624 17827 39671 48810 58762 21644 34109 27259 66544\n",
            " 58828 22445 18857 33886 70252  1519 45867 12710 36778 45809 49143 66867\n",
            " 51704 55581 48405 42276 20900 58828 62300 57799 35071 19720 70252  9452\n",
            " 27632 42276 62981 26214 14126 17827 51535 33886 50656 42276  1161     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[36778, 57525, 42276, 47769, 15039, 70252, 26203, 22445, 18857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "difuNX4awHnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee8efe66-dea7-4d95-cdcf-6148b7d515a2"
      },
      "source": [
        "embedding_matrix=np.zeros((num_words,EMB_DIM))\n",
        "#print(word2index)\n",
        "numNoEmb=0\n",
        "for word,i in word2index.items():\n",
        "    if i>num_words:\n",
        "        continue\n",
        "    embedding_vector=embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i]=embedding_vector\n",
        "    else:\n",
        "      numNoEmb+=1\n",
        "print(numNoEmb)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfxnS2FnLFEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "687fff18-3e42-4d7e-edb9-b4e5730fe32f"
      },
      "source": [
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import Input,Dense, CuDNNLSTM,LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation,Dropout,Add\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.initializers import Constant\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "HIDDEN_UNITS=256\n",
        "\"\"\"\n",
        "Bidirectional LSTM: Others Inspired Encoder-Decoder-seq2seq\n",
        "\"\"\"\n",
        "encoder_inputs = Input(shape=(MAX_LENGTH,))\n",
        "encoder_embedding = encoder_embedding_layer(num_words,EMB_DIM,embeddings_initializer=Constant(embedding_matrix),input_length=MAX_LENGTH,trainable=False)(encoder_inputs)\n",
        "encoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True)\n",
        "encoder_LSTM_R = LSTM(HIDDEN_UNITS, return_state=True, go_backwards=True)\n",
        "encoder_outputs_R, state_h_R, state_c_R = encoder_LSTM_R(encoder_embedding)\n",
        "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "\n",
        "final_h = Add()([state_h, state_h_R])\n",
        "final_c = Add()([state_c, state_c_R])\n",
        "encoder_states = [final_h, final_c]\n",
        "\n",
        "\"\"\"\n",
        "decoder\n",
        "\"\"\"\n",
        "decoder_inputs = Input(shape=(MAX_LENGTH,))\n",
        "decoder_embedding = decoder_embedding_layer(num_words,EMB_DIM,embeddings_initializer=Constant(embedding_matrix),input_length=MAX_LENGTH,trainable=False)(decoder_inputs)\n",
        "decoder_LSTM = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=encoder_states) \n",
        "decoder_dense = Dense(num_words, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model= Model(inputs=[encoder_inputs,decoder_inputs], outputs=decoder_outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.0001),    \n",
        "              metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model_seq2seq.png')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-91515e42e6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mencoder_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mencoder_LSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_UNITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mencoder_LSTM_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_UNITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo_backwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder_embedding_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmzMab8fTb4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}