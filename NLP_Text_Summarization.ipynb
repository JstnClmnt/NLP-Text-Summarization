{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-Summarization",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JstnClmnt/NLP-Text-Summarization/blob/practice/NLP_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruSXNIBlSo6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import re\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "275RJ-74TJUi",
        "colab_type": "code",
        "outputId": "6bc85034-0328-4ef8-b8c6-a9ff1c782221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJB2GnwJUZJU",
        "colab_type": "code",
        "outputId": "df28988d-ce93-4284-eb58-2de96d97cfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/drive/Team Drives/AI Lords/NLP-Text-Summarization/data/news_summary_more.csv\",encoding=\"latin-1\")\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUBzG4lWrCW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
        "df['headlines'] = df['headlines'].str.replace(\"[^a-zA-Z#]\",\" \")\n",
        "df=df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG7jkRpCUsPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.sample(n=1500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ece8p5BI2R",
        "colab_type": "code",
        "outputId": "291e90e6-ae3e-41b8-bda7-7dbb724d3c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "VOCAB_SIZE = 10000\n",
        "tokenizer = Tokenizer(oov_token=1,num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(df[\"text\"])\n",
        "article_sequences = tokenizer.texts_to_sequences(df[\"text\"])\n",
        "art_word_index = tokenizer.word_index\n",
        "len(art_word_index)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkW7llv3BxJI",
        "colab_type": "code",
        "outputId": "4d101615-86a5-4e38-a389-f03b503712a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "art_word_index_1500 = {}\n",
        "counter = 0\n",
        "for word in art_word_index.keys():\n",
        "    if art_word_index[word] == 0:\n",
        "        print(\"found 0!\")\n",
        "        break\n",
        "    if art_word_index[word] > VOCAB_SIZE:\n",
        "        continue\n",
        "    else:\n",
        "        art_word_index_1500[word] = art_word_index[word]\n",
        "        counter += 1\n",
        "print(counter)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Z46WZBCH8f",
        "colab_type": "code",
        "outputId": "c26848b7-796a-4ed8-9e71-e81ab4cd0a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.fit_on_texts(df[\"headlines\"])\n",
        "summary_sequences = tokenizer.texts_to_sequences(df[\"headlines\"])\n",
        "sum_word_index = tokenizer.word_index\n",
        "len(sum_word_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12098"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owWhmVpICXfO",
        "colab_type": "code",
        "outputId": "39a4d34f-f8c7-425a-cacc-6f6730344768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum_word_index_1500 = {}\n",
        "counter = 0\n",
        "for word in sum_word_index.keys():\n",
        "    if sum_word_index[word] == 0:\n",
        "        print(\"found 0!\")\n",
        "        break\n",
        "    if sum_word_index[word] > VOCAB_SIZE:\n",
        "        continue\n",
        "    else:\n",
        "        sum_word_index_1500[word] = sum_word_index[word]\n",
        "        counter += 1\n",
        "print(counter)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdIkHeY5pbOW",
        "colab_type": "code",
        "outputId": "91757c11-c3cd-42b7-a406-d968e73cbe2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(article_sequences, summary_sequences, test_size=0.20, random_state=42)\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7677, 10, 21, 14, 4900, 220, 426, 726, 1890, 839, 104, 3, 1661, 62, 1510, 1172, 5, 7678, 2, 1076, 134, 68, 11, 413, 25, 1345, 109, 41, 4901, 366, 4902, 5, 2, 7679, 791, 2, 328, 248, 91, 8, 4, 2359, 1028, 4903, 6, 515, 7680, 8, 2865, 53, 4904, 1418, 1159, 7, 2746, 1011, 3, 2, 3653]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IqWLGE2v3-h",
        "colab_type": "code",
        "outputId": "6f2d36fc-37a1-4905-bd20-725979d6d73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-18 20:06:01--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-05-18 20:06:01--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1       27%[====>               ] 228.07M  6.97MB/s    eta 67s    ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E767o2kOv7QC",
        "colab_type": "code",
        "outputId": "7da0ff13-d80f-4e4c-bb81-07df021e2b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip \"glove.6B.zip\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xl0omApv-UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.300d.txt',encoding=\"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iogkAHIowA3M",
        "colab_type": "code",
        "outputId": "60a750b9-4c53-4b4c-ad55-3a65733a3e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "EMB_DIM=300\n",
        "num_words=VOCAB_SIZE+1\n",
        "print(\"Number of Words:\"+str(num_words))\n",
        "\n",
        "MAX_LENGTH = len(max(X_train, key=len))\n",
        "print(\"Max Length: \"+str(MAX_LENGTH))  # 271\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_sentences_X = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(X_test, maxlen=MAX_LENGTH, padding='post')\n",
        "train_sentences_Y= pad_sequences(y_train, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_Y= pad_sequences(y_test, maxlen=MAX_LENGTH, padding='post')\n",
        "#y_train=to_categorical(y_train)\n",
        "#y_test=to_categorical(y_test)\n",
        "print(train_sentences_X[0])\n",
        "print(train_sentences_Y[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Words:10001\n",
            "Max Length: 68\n",
            "[7677   10   21   14 4900  220  426  726 1890  839  104    3 1661   62\n",
            " 1510 1172    5 7678    2 1076  134   68   11  413   25 1345  109   41\n",
            " 4901  366 4902    5    2 7679  791    2  328  248   91    8    4 2359\n",
            " 1028 4903    6  515 7680    8 2865   53 4904 1418 1159    7 2746 1011\n",
            "    3    2 3653    0    0    0    0    0    0    0    0    0]\n",
            "[4282  490    9  706   91    8 1324 1306    4 5735    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "difuNX4awHnQ",
        "colab_type": "code",
        "outputId": "19f9d0c5-33e0-406c-8310-d593551fef12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_art=np.zeros((num_words,EMB_DIM))\n",
        "numNoEmb=0\n",
        "#print(word2index)\n",
        "for word,i in art_word_index_1500.items():\n",
        "    embedding_vector=embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_art[i]=embedding_vector\n",
        "    else:\n",
        "      numNoEmb+=1\n",
        "print(numNoEmb)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxG9s6eFD44S",
        "colab_type": "code",
        "outputId": "40837b5e-2b99-41bd-b4a4-a0d982f62e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_sum=np.zeros((num_words,EMB_DIM))\n",
        "#print(word2index)\n",
        "numNoEmb=0\n",
        "for word,i in sum_word_index_1500.items():\n",
        "    if i>num_words:\n",
        "        continue\n",
        "    embedding_vector=embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_sum[i]=embedding_vector\n",
        "    else:\n",
        "      numNoEmb+=1\n",
        "print(numNoEmb)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfxnS2FnLFEO",
        "colab_type": "code",
        "outputId": "21ee8210-9bb1-4744-a747-0f26fce732e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import Input,Dense, CuDNNLSTM,LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation,Dropout,Add\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.initializers import Constant\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "HIDDEN_UNITS=200\n",
        "\n",
        "encoder_inputs = Input(shape=(MAX_LENGTH,))\n",
        "encoder_embedding = Embedding(num_words,EMB_DIM,embeddings_initializer=Constant(embedding_matrix_art),input_length=MAX_LENGTH,trainable=False,mask_zero=True)(encoder_inputs)\n",
        "encoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "\n",
        "decoder_inputs = Input(shape=(MAX_LENGTH,))\n",
        "decoder_embedding = Embedding(num_words,EMB_DIM,embeddings_initializer=Constant(embedding_matrix_sum),input_length=MAX_LENGTH,trainable=False,mask_zero=True)(decoder_inputs)\n",
        "decoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# dense_layer = Dense(VOCAB_SIZE, activation='softmax')\n",
        "outputs = TimeDistributed(Dense(num_words, activation='softmax'))(decoder_outputs)\n",
        "\n",
        "model= tf.keras.Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),    \n",
        "              metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model_seq2seq.png')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 68)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 68)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 68, 300)      3000300     input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 68, 300)      3000300     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, 200), (None, 400800      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 68, 200), (N 400800      embedding_7[0][0]                \n",
            "                                                                 lstm_7[0][1]                     \n",
            "                                                                 lstm_7[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 68, 10001)    2010201     lstm_8[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 8,812,401\n",
            "Trainable params: 2,811,801\n",
            "Non-trainable params: 6,000,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmzMab8fTb4E",
        "colab_type": "code",
        "outputId": "1eae7b2a-af80-42e8-a6d6-3b8061e43cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_samples_train = len(train_sentences_Y)\n",
        "print(num_samples_train)\n",
        "decoder_output_data_train = np.ones(shape=(num_samples_train, MAX_LENGTH, num_words))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UrgAgqZUPg4",
        "colab_type": "code",
        "outputId": "58f18ebf-2aca-4bf1-cc3e-c22b7358143c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_samples_test = len(test_sentences_Y)\n",
        "print(num_samples_test)\n",
        "decoder_output_data_test = np.ones(shape=(num_samples_test, MAX_LENGTH, num_words))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oGKNZojVHxu",
        "colab_type": "code",
        "outputId": "640f98be-f7ba-4acd-f03a-d69dfc626b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "save = ModelCheckpoint('best_model.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "history = model.fit([train_sentences_X, train_sentences_Y], \n",
        "                     decoder_output_data_train, \n",
        "                     epochs=100, \n",
        "                     batch_size=32,\n",
        "                     validation_data=([test_sentences_X, test_sentences_Y], decoder_output_data_test),\n",
        "                     callbacks=[save])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1200 samples, validate on 300 samples\n",
            "Epoch 1/100\n",
            "1200/1200 [==============================] - 27s 22ms/sample - loss: 0.1422 - acc: 2.5851e-04 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1200/1200 [==============================] - 18s 15ms/sample - loss: 0.1422 - acc: 2.5851e-04 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            "1200/1200 [==============================] - 17s 15ms/sample - loss: 0.1422 - acc: 2.5851e-04 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            "1200/1200 [==============================] - 17s 14ms/sample - loss: 0.1422 - acc: 2.5851e-04 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            "1200/1200 [==============================] - 18s 15ms/sample - loss: 0.1422 - acc: 2.5851e-04 - val_loss: 0.1430 - val_acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            " 160/1200 [===>..........................] - ETA: 12s - loss: 0.1386 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c023d0c64b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sentences_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences_Y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output_data_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                      callbacks=[save])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3059\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3060\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[0;32m-> 3061\u001b[0;31m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[1;32m   3062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBMwR2U-fIVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}